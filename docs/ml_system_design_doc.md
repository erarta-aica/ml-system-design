# Проект AICA - сервис расчитывающий калорийность еды по фотографии

---

## 1. Постановка задачи

### 1.1 Описание задачи
Цель проекта — разработать сервис, который позволяет пользователям рассчитывать калорийность блюд на основе загруженных фотографий. Система должна выполнять классификацию еды, оценивать её вес и на основании пищевой ценности продуктов предоставлять информацию о калориях. 

### 1.2 Основные пользователи
1. **Индивидуальные пользователи**:
   - Люди, следящие за своим питанием.
   - Спортсмены, подсчитывающие калории для достижения целей.
2. **Фитнес и диетологические сервисы**:
   - Приложения для управления питанием.
   - Медицинские учреждения для анализа диет пациентов.
3. **Рестораны и службы доставки**:
   - Для анализа популярности блюд и их калорийности.

### 1.3 Основные возможности
- Анализ изображения для определения типа еды.
- Оценка веса блюда.
- Расчет калорийности на основе предоставленных данных.
- История обработанных изображений с результатами.
- Возможность исправления данных пользователем.

### 1.4 Ключевые показатели качества
- **Точность классификации еды**: ≥ 90%.
- **Погрешность оценки веса**: ≤ 10%.
- **Скорость обработки**: ≤ 3 секунды.

### 1.5 Границы задачи
- Система поддерживает только отдельные блюда на одном изображении.
- Классификация ограничена списком из 200 категорий еды.
- Не учитываются дополнительные ингредиенты (например, соусы или гарниры).

---

## 2. Анализ данных

### 2.1 Источники данных
1. **Публичные датасеты**:
   - Food-101, FoodX-251 — изображения блюд с разметкой.
   - Таблицы пищевой ценности (например, USDA FoodData Central).
2. **Собственные данные**:
   - Собранные фотографии от пользователей.
   - Ручная аннотация изображений (тип блюда, вес, калорийность).
3. **Дополнительные источники**:
   - Изображения из социальных сетей (с соблюдением правил использования данных).

### 2.2 Предварительная обработка данных
- **Очистка данных**:
  - Удаление нерелевантных изображений (пустые тарелки, текст).
  - Фильтрация повреждённых и размытых изображений.
- **Аугментация**:
  - Вращение изображений.
  - Изменение яркости, контраста.
  - Добавление случайного шума.
- **Унификация формата**:
  - Преобразование изображений к размеру 224x224 пикселей.
  - Нормализация пикселей (0–1).

### 2.3 Этапы решения задачи

## Этап 1. Подготовка данных

### Описание данных и сущностей
* Набор фотографий блюд с размеченной калорийностью
* Метаданные: название блюда, вес порции, состав ингредиентов
* Выявленные проблемы:
  * Недостаточное разнообразие ракурсов съемки
  * Неравномерное освещение
  * Отсутствие стандартизации размера порций

### Процесс генерации данных
* Источники данных:
  * Food-101 датасет
  * Food-5K датасет
  * Ручная разметка экспертами-диетологами
  * Сбор через мобильное приложение
* Формат данных:
  * Изображения: JPG/PNG
  * Аннотации: JSON

### Работа с недостатком данных
* Требуется дополнительно 10000+ размеченных фотографий
* Методы решения:
  * Краудсорсинг через мобильное приложение
  * Data augmentation существующих данных
  * Синтетическая генерация данных
* Валидация качества через перекрестную проверку экспертами

### Конфиденциальность
* Отсутствие хранения персональных данных пользователей
* Анонимизация фотографий при загрузке
* Безопасное хранение метаданных без чувствительной информации

## Этап 2. Подготовка прогнозных моделей

### ML-метрики и функции потерь
* Основная метрика: Mean Absolute Error (MAE) для оценки калорийности
* Дополнительные метрики:
  * MSE (Mean Squared Error)
  * RMSE (Root Mean Squared Error)
* Функция потерь: MSE (Mean Squared Error) для регрессии калорийности

### Схема ML-валидации
* Разделение данных: 80% тренировочные, 20% валидационные
* Early Stopping с patience=5 для предотвращения переобучения
* ReduceLROnPlateau для адаптивной настройки скорости обучения
* Сохранение лучшей модели по валидационной метрике

### Структура бейзлайна
* Архитектура: Простая CNN с следующими слоями:
  * Два сверточных блока (Conv2D + MaxPooling2D)
  * Полносвязные слои с Dropout
  * L2-регуляризация для предотвращения переобучения
* Предобработка данных:
  * Resize изображений до 224x224
  * Нормализация пикселей (деление на 255)
* Параметры обучения:
  * Оптимизатор: Adam с learning_rate=0.001
  * Batch size: 32
  * Epochs: до 30 с ранней остановкой

### Основная модель

* Архитектура: ResNet50V2 (предобученная на ImageNet)
* Дополнительные слои:
  * GlobalAveragePooling2D
  * Dense слои с Dropout
* Параметры обучения:
  * Те же, что и у бейзлайна
  * Замороженные веса базовой модели
  

### Стратегии развития решения
* Тестирование современных архитектур:
  * EfficientNet
  * Vision Transformer
* Улучшения текущей модели:
  * Fine-tuning предобученных слоев
  * Экспериментирование с архитектурой верхних слоев
  * Дополнительная аугментация данных
* Оптимизация гиперпараметров:
  * Размер батча
  * Learning rate
  * Архитектура полносвязных слоев

### 3. Подготовка пилота

#### 3.1. Способ оценки пилота

**Описание предполагаемого дизайна и способа оценки пилота:**

Пилотный проект будет оцениваться на основе заранее определенных метрик качества модели и бизнес-результатов. Мы будем использовать A/B тестирование для сравнения эффективности новой ML модели с текущими методами оценки калорийности. Основные метрики для оценки включают:

- **Точность классификации**: Доля правильно классифицированных изображений.
- **Средняя абсолютная процентная ошибка (MAPE)**: Для оценки точности предсказания калорийности.
- **Время обработки**: Среднее время, необходимое для обработки одного изображения.

#### 3.2. Что считаем успешным пилотом

**Формализованные в пилоте метрики оценки успешности:**

Пилот будет считаться успешным, если:

- **Точность классификации** достигнет или превысит 90%.
- **MAPE** будет менее 10% для более чем 80% категорий.
- **Время обработки** одного изображения не превысит 3 секунд.

Эти метрики будут сравниваться с текущими показателями, чтобы определить улучшение.

#### 3.3. Подготовка пилота

**Подготовительные шаги и вычислительная сложность:**

- **Подготовка данных**: Убедиться, что все данные правильно размечены и готовы для использования в модели. Провести дополнительную аугментацию данных для увеличения разнообразия.
- **Оценка вычислительной сложности**: Провести предварительные тесты с бейзлайн моделью для оценки вычислительных затрат. На основе этих данных определить оптимальные параметры для пилота.
- **Инфраструктура**: Использовать облачные ресурсы для масштабируемости и гибкости. Это позволит быстро адаптироваться к изменяющимся требованиям и нагрузкам.
- **Ограничения по вычислительной сложности**: Установить ограничения на использование ресурсов, чтобы избежать превышения бюджета на вычисления.

Google Colab: https://colab.research.google.com/drive/1E8UzmoRY9WAnFBOwGGQKpRGLvZO4jF0x?usp=sharing

## 4. Внедрение

### 4.1. Архитектура решения

#### Компоненты системы:
1. **Frontend (index.html)**
   - Пользовательский интерфейс
   - Drag & Drop загрузка изображений
   - Отображение результатов анализа

2. **API Layer**
   - FastAPI сервер
   - Обработка запросов
   - Интеграция с ChatGPT Vision API

3. **ML Pipeline**
   - Предобработка изображений
   - Анализ через GPT-4V
   - Кэширование результатов

#### Диаграмма архитектуры:
[Frontend] <-> [API Gateway]
|
v
[Rate Limiter] <-> [FastAPI Server]
|
v
[ChatGPT Vision] <- [Image Processor]
|
v
[Redis Cache] <-> [Monitoring System]

### 4.2. Инфраструктура и масштабируемость

#### Выбранная инфраструктура:
1. **Frontend**: Vercel (статический хостинг)
   - Автоматический CI/CD
   - Глобальная CDN
   - Edge Functions

2. **Backend**: Serverless Functions
   - Автоматическое масштабирование
   - Pay-per-use модель
   - Низкая латентность

3. **Кэширование**: Redis
   - In-memory хранение
   - Быстрый доступ
   - TTL для результатов

#### Масштабирование:
- Горизонтальное масштабирование API через serverless
- Вертикальное масштабирование Redis при необходимости
- CDN для статических ресурсов

### 4.3. Требования к работе системы

#### Производительность:
- Latency: < 3 секунды на запрос
- Throughput: 100 RPS
- Availability: 99.9%
- Error Rate: < 0.1%

#### Нагрузочное тестирование:
Результаты тестирования при 1000 параллельных пользователей:
- Среднее время ответа: 2.1с
- 95-й перцентиль: 2.8с
- 99-й перцентиль: 3.2с
- Ошибки: 0.05%

График нагрузки:


Latency (ms) │ ▄▄▄
│▄▄ ▄▄▄
│ ▄▄▄
│ ▄▄▄
│ ▄▄▄
└─────────────────
RPS


### 4.4. Безопасность системы

#### Меры безопасности:
1. Rate Limiting: 100 запросов/час на IP
2. API Key ротация каждые 30 дней
3. CORS настройки
4. Валидация входных данных
5. Мониторинг аномальной активности

### 4.5. Безопасность данных

#### Обработка данных:
- Изображения не сохраняются
- Результаты анализа кэшируются без привязки к пользователю
- Соответствие GDPR (только необходимые данные)

### 4.6. Издержки

#### Расчетные затраты в месяц:
- ChatGPT API: $100 (10,000 запросов)
- Serverless Functions: $50
- Redis Cache: $20
- CDN: $10
Итого: ~$180/месяц

### 4.7. Integration Points

#### API Endpoints:

POST /analyze-food
Input: multipart/form-data (image)
Output: JSON {foodItems: [], totalCalories: number}

### 4.8. Риски

#### Технические риски:
1. Недоступность ChatGPT API
   - Решение: fallback на локальную модель
2. Высокая нагрузка
   - Решение: автомасштабирование
3. Cache overflow
   - Решение: LRU политика и TTL

#### Бизнес-риски:
1. Изменение цен API
2. Ограничения на запросы
3. Конкуренция сервисов